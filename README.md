# **QA with Documents using LangChain & AWS Bedrock**

This project implements a **Question-Answering (QA) system** using **LangChain**, **FAISS**, and **AWS Bedrock**. The system allows users to ask questions from uploaded documents (PDFs) and retrieves relevant answers using **Amazon Bedrock's LLM models**.

---

## **ğŸš€ Features**
- **Retrieval-Augmented Generation (RAG)** using **FAISS**
- **Amazon Bedrock Titan Models** for LLM and embeddings
- **Streamlit UI** for user interaction
- **Custom prompt engineering** for better responses
- **Automatic vector store update** for new documents

---

## **ğŸ“‚ Project Structure**
```
LLMOPS/
â”‚â”€â”€ app.py                # Streamlit-based UI for user interaction
â”‚â”€â”€ QA_system/
â”‚   â”‚â”€â”€ ingestion.py       # Data ingestion and FAISS vector store creation
â”‚   â”‚â”€â”€ retrivalandgeneration.py  # LLM interaction & response generation
â”‚â”€â”€ faiss_index/          # Stored FAISS index
â”‚â”€â”€ README.md             # Project documentation
â”‚â”€â”€ requirements.txt      # Dependencies
```

---

## **ğŸ“š Libraries Used**
### **Core Dependencies:**
- [LangChain](https://github.com/hwchase17/langchain) - Framework for LLM applications
- [Amazon Bedrock](https://aws.amazon.com/bedrock/) - Serverless AI model inference
- [FAISS](https://github.com/facebookresearch/faiss) - Efficient similarity search for vector embeddings
- [Streamlit](https://streamlit.io/) - Interactive UI for Q&A
- [Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) - AWS SDK for Python

### **Additional Dependencies:**
- `json`, `os`, `sys` - Standard Python libraries

---

## **ğŸ›  Setup Instructions**

### **1ï¸âƒ£ Clone the Repository**
```sh
git clone https://github.com/your-repo/LLMOPS.git
cd LLMOPS
```

### **2ï¸âƒ£ Install Dependencies**
```sh
pip install -r requirements.txt
```

### **3ï¸âƒ£ Configure AWS Credentials**
Ensure that you have access to **AWS Bedrock** and that your credentials are set up:
```sh
aws configure
```

### **4ï¸âƒ£ Run the Application**
```sh
streamlit run app.py
```

---

## **ğŸ” Usage**
### **1ï¸âƒ£ Upload Documents & Update Vector Store**
- Click **"vectors update"** in the sidebar to process new PDFs.

### **2ï¸âƒ£ Ask Questions**
- Type your question in the input box and press Enter.
- The system retrieves relevant document snippets and generates an answer.

### **3ï¸âƒ£ Use Llama Model**
- Click **"llama model"** to generate a response from the **Titan model**.

---

## **ğŸ›  Troubleshooting**
### **âš ï¸ Common Issues**
âŒ **AccessDeniedException on Bedrock** â†’ Ensure model access is enabled in AWS Console.
âŒ **FAISS Index Not Found** â†’ Run `vectors update` before querying.
âŒ **ModuleNotFoundError** â†’ Run `pip install -r requirements.txt`.

---

## **ğŸ“Œ Future Enhancements**
âœ… Support for multiple document formats (DOCX, TXT, etc.)
âœ… Fine-tuned prompts for better accuracy
âœ… Deployment on AWS Lambda or EC2

---

## **ğŸ“œ License**
This project is licensed under **MIT License**.

---

## **ğŸ“§ Contact**
ğŸ“© **Email:** your.email@example.com  
ğŸ™ **GitHub:** [your-repo](https://github.com/your-repo)

